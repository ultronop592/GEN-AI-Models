{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Generative AI Project"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["!pip install transformers torch"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import torch\nimport transformers"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["model = transformers.AutoModelForCausalLM.from_pretrained('gpt2')"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def generate_text(prompt):\n    inputs = tokenizer(prompt, return_tensors='pt')\n    outputs = model.generate(inputs['input_ids'], max_length=100)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)"]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python", "version": "3.8", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8"}, "colab": {"name": "Generative AI Project", "version": 0.1, "language": "en", "license": "license", "metadata": {"gpu": true}}}, "nbformat": 4, "nbformat_minor": 5}